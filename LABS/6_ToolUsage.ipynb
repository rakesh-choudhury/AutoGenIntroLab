{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool Use\n",
    "\n",
    "Tools are pre-defined functions that agents can use. Instead of writing arbitrary code, agents can call tools to perform actions, such as searching the web, performing calculations, reading files, or calling remote APIs. Because you can control what tools are available to an agent, you can control what actions an agent can perform.\n",
    "\n",
    "note: Tool use is currently only available for LLMs that support OpenAI-comaptible tool call API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import config_list_from_json\n",
    "\n",
    "myModelname=\"gpt-35-turbo\" #your model Name\n",
    "\n",
    "#Read config File AOAI_CONFIG_LIST.json\n",
    "config_list = config_list_from_json(\n",
    "    env_or_file=\"/Users/rakeshchoudhury/Git/AzureAILab/AutoGenIntroLab/AOAI_CONFIG_LIST.json\",\n",
    "    filter_dict={\"model\": myModelname}\n",
    "    )\n",
    "\n",
    "# LLM config file for myModelname (your model Name)\n",
    "\n",
    "llm_myModelName_config={\n",
    "        \"timeout\": 600,\n",
    "        \"seed\": 42,\n",
    "        \"config_list\": config_list,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Creating Tools\n",
    "\n",
    "Tools can be created as regular Python functions. For example, letâ€™s create a calculator tool which can only perform a single operation at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal\n",
    "\n",
    "Operator = Literal[\"+\", \"-\", \"*\", \"/\"]\n",
    "\n",
    "\n",
    "def calculator(a: int, b: int, operator: Annotated[Operator, \"operator\"]) -> int:\n",
    "    if operator == \"+\":\n",
    "        return a + b\n",
    "    elif operator == \"-\":\n",
    "        return a - b\n",
    "    elif operator == \"*\":\n",
    "        return a * b\n",
    "    elif operator == \"/\":\n",
    "        return int(a / b)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid operator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Registering Tools\n",
    "\n",
    "Once you have created a tool, you can register it with the agents that are involved in conversation.\n",
    "\n",
    "TIP: Always provide a clear and concise description for the tool as it helps the agent's underlying LLM to understand the tool's usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.calculator(a: int, b: int, operator: Annotated[Literal['+', '-', '*', '/'], 'operator']) -> int>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from autogen import ConversableAgent\n",
    "\n",
    "# Let's first define the assistant agent that suggests tool calls.\n",
    "assistant = ConversableAgent(\n",
    "    name=\"Assistant\",\n",
    "    system_message=\"You are a helpful AI assistant. \"\n",
    "    \"You can help with simple calculations. \"\n",
    "    \"Return 'TERMINATE' when the task is done or fail.\",\n",
    "    llm_config=llm_myModelName_config,\n",
    ")\n",
    "\n",
    "# The user proxy agent is used for interacting with the assistant agent\n",
    "# and executes tool calls.\n",
    "user_proxy = ConversableAgent(\n",
    "    name=\"User\",\n",
    "    llm_config=False,\n",
    "    is_termination_msg=lambda msg: msg.get(\"content\") is not None and \"TERMINATE\" in msg[\"content\"],\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "\n",
    "#Function description\n",
    "funDes=\"This is a simple calculator, recieve 2 arguments and an operator and return the result of the operation.\"\n",
    "\n",
    "# Register the tool signature with the assistant agent.\n",
    "assistant.register_for_llm(name=\"calculator\", description=funDes)(calculator)\n",
    "\n",
    "# Register the tool function with the user proxy agent.\n",
    "user_proxy.register_for_execution(name=\"calculator\")(calculator)\n",
    "\n",
    "#TIP Always provide a clear and concise description for the tool as it helps the agent's underlying LLM to understand the tool's usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Using Tool\n",
    "\n",
    "Once the tool is registered, we can use it in conversation. In the code below, we ask the assistant to perform some arithmetic calculation using the calculator tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUser\u001b[0m (to Assistant):\n",
      "\n",
      "What is 666 + 3333?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mAssistant\u001b[0m (to User):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_z5YVDj2C9XY16SoHl13HqZCW): calculator *****\u001b[0m\n",
      "Arguments: \n",
      "{\"a\": 666, \"b\": 3333, \"operator\": \"+\"}\n",
      "\u001b[32m***************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION calculator...\u001b[0m\n",
      "\u001b[33mUser\u001b[0m (to Assistant):\n",
      "\n",
      "\u001b[33mUser\u001b[0m (to Assistant):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_z5YVDj2C9XY16SoHl13HqZCW) *****\u001b[0m\n",
      "3999\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mAssistant\u001b[0m (to User):\n",
      "\n",
      "3999\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mUser\u001b[0m (to Assistant):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mAssistant\u001b[0m (to User):\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chat_result = user_proxy.initiate_chat(assistant, message=\"What is 666 + 3333?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
